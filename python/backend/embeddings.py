import os
import uuid
import time
import PyPDF2
import requests
import google.generativeai as genai
from qdrant_client import QdrantClient
from document import Document

# Configurar Google Gemini para embeddings
print("üîÑ Configurando Google Gemini para embeddings...")
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
print("‚úÖ Google Gemini configurado")

# Modelos disponibles con rotaci√≥n para evitar l√≠mites de cuota
EMBEDDING_MODELS = [
    'models/text-embedding-004',  # Modelo principal
]

# √çndice para rotaci√≥n de modelos (se incrementa en cada llamada)
_model_index = 0

def get_next_embedding_model():
    """Obtiene el siguiente modelo de la lista para rotaci√≥n"""
    global _model_index
    model = EMBEDDING_MODELS[_model_index % len(EMBEDDING_MODELS)]
    _model_index += 1
    return model

def generate_embedding(text: str, task_type=None, retry_delay=2) -> list:
    """
    Genera embedding usando Google Gemini
    Usa el modelo 'models/text-embedding-004' que es compatible con n8n
    Incluye delay autom√°tico para evitar rate limiting
    
    Args:
        text: Texto para generar embedding
        task_type: None para compatibilidad con n8n, o 'retrieval_document'/'retrieval_query' si se especifica
        retry_delay: Tiempo de espera entre reintentos
    
    IMPORTANTE: n8n NO especifica task_type, as√≠ que usamos None por defecto
    para que los embeddings sean compatibles con las b√∫squedas de n8n
    """
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # Si task_type es None, no lo pasamos (comportamiento por defecto de n8n)
            embed_params = {
                'model': 'models/text-embedding-004',
                'content': text
            }
            if task_type is not None:
                embed_params['task_type'] = task_type
                
            result = genai.embed_content(**embed_params)
            # Peque√±o delay despu√©s de cada llamada exitosa para evitar rate limiting
            time.sleep(0.5)
            return result['embedding']
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Resource exhausted" in error_msg:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (attempt + 1)
                    print(f"‚ö†Ô∏è Rate limit alcanzado. Esperando {wait_time}s antes de reintentar...")
                    time.sleep(wait_time)
                else:
                    print(f"‚ùå Error generando embedding despu√©s de {max_retries} intentos: {e}")
                    raise
            else:
                print(f"‚ùå Error generando embedding: {e}")
                raise

def get_qdrant_client():
    """Obtener cliente de Qdrant con configuraci√≥n desde variables de entorno"""
    qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
    qdrant_api_key = os.getenv('QDRANT_API_KEY', None)
    
    if qdrant_api_key:
        # Qdrant Cloud o servidor con autenticaci√≥n
        # Usar prefer_grpc=False para forzar REST API en lugar de gRPC
        return QdrantClient(
            url=qdrant_url,
            api_key=qdrant_api_key,
            prefer_grpc=False  # Usar REST API solamente
        )
    else:
        # Qdrant local sin autenticaci√≥n
        return QdrantClient(url=qdrant_url)

def create_embeddings(chatbot_id, file_name):
    """Extraer texto del PDF y crear embeddings en Qdrant"""
    # Extraer el texto del pdf
    with open(os.path.join('pdf_files', file_name), 'rb') as pdf_file:
        pdf_reader = PyPDF2.PdfReader(pdf_file)

        documents = []
        for page_num, page in enumerate(pdf_reader.pages):
            document = Document(
                doc_id=str(uuid.uuid4()),
                content=page.extract_text(),
                metadata={'page_number': str(page_num), 'filename': file_name}
            )
            documents.append(document)

    # Conectar a Qdrant
    client = get_qdrant_client()
    
    # Crear colecci√≥n si no existe
    collections = client.get_collections().collections
    collection_exists = any(col.name == chatbot_id for col in collections)
    
    if not collection_exists:
        client.create_collection(
            collection_name=chatbot_id,
            vectors_config=VectorParams(
                size=768,  # Dimensi√≥n del modelo paraphrase-multilingual-mpnet-base-v2
                distance=Distance.COSINE
            )
        )
    
    # Crear embeddings y guardar en Qdrant
    points = []
    for doc in documents:
        # Generar embedding
        vector = embedding_model.encode(doc.content).tolist()
        
        # Crear punto
        point = PointStruct(
            id=str(uuid.uuid4()),
            vector=vector,
            payload={
                'content': doc.content,
                'metadata': doc.metadata
            }
        )
        points.append(point)
    
    # Subir puntos a Qdrant
    client.upsert(
        collection_name=chatbot_id,
        points=points
    )

def add_pdf_to_collection(collection_name, file_path, file_name):
    """
    Agregar un PDF a una colecci√≥n existente de Qdrant
    """
    print(f"üìÑ Procesando PDF: {file_name}")
    
    # Extraer el texto del PDF
    with open(file_path, 'rb') as pdf_file:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        total_pages = len(pdf_reader.pages)
        print(f"üìñ Total de p√°ginas: {total_pages}")

        documents = []
        for page_num, page in enumerate(pdf_reader.pages):
            content = page.extract_text()
            if content.strip():  # Solo agregar p√°ginas con contenido
                document = Document(
                    doc_id=str(uuid.uuid4()),
                    content=content,
                    metadata={
                        'page_number': str(page_num + 1),
                        'filename': file_name,
                        'total_pages': str(total_pages)
                    }
                )
                documents.append(document)
        
        print(f"‚úÖ Extra√≠das {len(documents)} p√°ginas con contenido")

    # Verificar que la colecci√≥n existe usando REST API
    qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
    api_key = os.getenv('QDRANT_API_KEY', None)
    
    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['api-key'] = api_key
    
    try:
        response = requests.get(
            f"{qdrant_url}/collections/{collection_name}",
            headers=headers,
            timeout=10
        )
        
        if response.status_code == 200:
            collection_info = response.json()
            points_count = collection_info.get('result', {}).get('points_count', 0)
            print(f"‚úÖ Colecci√≥n '{collection_name}' encontrada: {points_count} puntos existentes")
        else:
            print(f"‚ùå Error: La colecci√≥n '{collection_name}' no existe (status: {response.status_code})")
            raise ValueError(f"La colecci√≥n '{collection_name}' no existe")
    except requests.RequestException as e:
        print(f"‚ùå Error al verificar colecci√≥n: {e}")
        raise ValueError(f"No se pudo conectar a Qdrant: {e}")
    
    # Crear embeddings y puntos para Qdrant
    print("üîÑ Generando embeddings...")
    points = []
    for i, doc in enumerate(documents):
        # Generar embedding usando Google Gemini (sin task_type, igual que n8n)
        vector = generate_embedding(doc.content)
        
        # Crear punto en formato dict para REST API
        # IMPORTANTE: n8n usa 'content' como campo principal
        point = {
            'id': str(uuid.uuid4()),
            'vector': vector,
            'payload': {
                'content': doc.content,  # n8n usa 'content'
                'metadata': doc.metadata
            }
        }
        points.append(point)
        
        if (i + 1) % 10 == 0:
            print(f"   Procesadas {i + 1}/{len(documents)} p√°ginas...")
    
    print(f"‚úÖ Embeddings generados para {len(points)} p√°ginas")
    
    # Subir puntos a Qdrant usando REST API
    try:
        payload = {
            'points': points
        }
        
        print(f"üîÑ Subiendo {len(points)} puntos a Qdrant...")
        response = requests.put(
            f"{qdrant_url}/collections/{collection_name}/points",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ PDF agregado exitosamente!")
            print(f"   Status: {result.get('status')}")
        else:
            print(f"‚ùå Error al subir puntos: {response.status_code} - {response.text}")
            raise ValueError(f"Error al subir puntos a Qdrant: {response.status_code}")
            
    except requests.RequestException as e:
        print(f"‚ùå Error al conectar con Qdrant: {e}")
        raise ValueError(f"No se pudo subir a Qdrant: {e}")
    
    # Verificar resultado final con REST API
    response = requests.get(
        f"{qdrant_url}/collections/{collection_name}",
        headers=headers,
        timeout=10
    )
    
    if response.status_code == 200:
        updated_info = response.json()
        total_points = updated_info.get('result', {}).get('points_count', 0)
        print(f"   Puntos totales en '{collection_name}': {total_points}")
        
        return {
            'pages_added': len(documents),
            'total_points': total_points,
            'filename': file_name
        }
    else:
        return {
            'pages_added': len(documents),
            'total_points': 'unknown',
            'filename': file_name
        }


def get_documents(collection_name, question, limit=8):
    """
    Buscar documentos relevantes en Qdrant usando b√∫squeda sem√°ntica
    Genera embedding de la pregunta y busca los documentos m√°s similares
    
    IMPORTANTE: Usa task_type=None para compatibilidad con n8n
    Usa limit=8 por defecto para obtener mejor contexto y permitir re-ranking por fecha
    """
    from datetime import datetime
    
    qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
    api_key = os.getenv('QDRANT_API_KEY', None)
    
    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['api-key'] = api_key
    
    try:
        # Nombres en espa√±ol para d√≠as y meses
        dias = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']
        meses = ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 
                 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre']
        
        # DEBUG: Ver qu√© query recibimos
        print(f"üîç Query recibida en semantic_search: '{question}'")
        
        # Enriquecer la pregunta con contexto temporal
        question_lower = question.lower()
        enriched_question = question
        target_date = None
        
        # Detectar referencias temporales y calcular la fecha correspondiente
        from datetime import timedelta
        import re
        now = datetime.now()
        
        # 1. Detectar referencias relativas (hoy, ma√±ana, ayer, etc.)
        # IMPORTANTE: Detectar frases m√°s espec√≠ficas PRIMERO (pasado ma√±ana antes que ma√±ana)
        if 'hoy' in question_lower or 'de hoy' in question_lower or 'esta lecci√≥n' in question_lower or 'lecci√≥n de hoy' in question_lower or 'actual' in question_lower or 'esta semana' in question_lower:
            target_date = now
            print(f"üìÖ Detectado: HOY")
        elif 'pasado ma√±ana' in question_lower or 'pasado-ma√±ana' in question_lower or 'pasadoma√±ana' in question_lower:
            target_date = now + timedelta(days=2)
            print(f"üìÖ Detectado: PASADO MA√ëANA")
        elif 'antes de ayer' in question_lower or 'anteayer' in question_lower or 'antesdeayer' in question_lower:
            target_date = now - timedelta(days=2)
            print(f"üìÖ Detectado: ANTES DE AYER")
        elif 'ma√±ana' in question_lower:
            target_date = now + timedelta(days=1)
            print(f"üìÖ Detectado: MA√ëANA ‚Üí {dias[target_date.weekday()]} {target_date.day} de {meses[target_date.month - 1]}")
        elif 'ayer' in question_lower:
            target_date = now - timedelta(days=1)
            print(f"üìÖ Detectado: AYER ‚Üí {dias[target_date.weekday()]} {target_date.day} de {meses[target_date.month - 1]}")
        else:
            # 2. Detectar fechas expl√≠citas en formato "DD de mes" (ej: "30 de octubre", "3 de noviembre")
            # Patr√≥n: n√∫mero + "de" + nombre_del_mes
            fecha_pattern = r'(\d{1,2})\s+de\s+(' + '|'.join(meses) + r')'
            match = re.search(fecha_pattern, question_lower)
            
            if match:
                dia_numero = int(match.group(1))
                mes_nombre = match.group(2)
                mes_numero = meses.index(mes_nombre) + 1
                
                # Construir la fecha con el a√±o actual
                from datetime import date
                try:
                    target_date = date(now.year, mes_numero, dia_numero)
                    print(f"üìÖ Detectado fecha expl√≠cita: {dia_numero} de {mes_nombre}")
                except ValueError:
                    # Fecha inv√°lida (ej: 31 de febrero)
                    print(f"‚ö†Ô∏è Fecha inv√°lida: {dia_numero} de {mes_nombre}")
                    target_date = None
        
        # Si detectamos una referencia temporal, enriquecer la pregunta
        if target_date:
            dia_semana = dias[target_date.weekday()]
            dia_numero = target_date.day
            mes = meses[target_date.month - 1]
            
            enriched_question = f"{question} {dia_semana} {dia_numero} de {mes}"
            print(f"üîç Pregunta enriquecida con contexto temporal: {enriched_question}")
        
        # Generar embedding SIN task_type para compatibilidad con n8n
        print(f"üîç Generando embedding para b√∫squeda (modo n8n compatible): {enriched_question}")
        question_vector = generate_embedding(enriched_question, task_type=None)
        
        if not question_vector:
            print("‚ùå Error: No se pudo generar el vector de la pregunta")
            return []
        
        print(f"‚úÖ Vector generado exitosamente (dimensi√≥n: {len(question_vector)})")
        
        # Buscar documentos similares usando b√∫squeda sem√°ntica
        # Aumentar limit a 20 para capturar todos los d√≠as de la lecci√≥n cuando hay fecha espec√≠fica
        # Luego se reduce a 'limit' despu√©s del re-ranking
        search_limit = 20 if target_date else limit
        
        payload = {
            "vector": question_vector,
            "limit": search_limit,
            "with_payload": True,
            "with_vector": False
            # SIN score_threshold - n8n no lo usa por defecto
        }
        
        # Si hay fecha espec√≠fica, agregar b√∫squeda h√≠brida con scroll
        # para garantizar que encontremos el documento exacto
        if target_date:
            dia_semana_target = dias[target_date.weekday()]
            dia_numero_target = str(target_date.day)
            mes_target = meses[target_date.month - 1]
            
            print(f"üîé B√∫squeda H√çBRIDA activada para: {dia_semana_target} {dia_numero_target} de {mes_target}")
            print(f"   - B√∫squeda vectorial: {search_limit} docs")
            print(f"   - B√∫squeda por scroll: revisando toda la colecci√≥n")
        
        print(f"üîé Buscando en Qdrant: {qdrant_url}/collections/{collection_name}/points/search")
        print(f"   - Limit: {search_limit} ({'ampliado para b√∫squeda por fecha' if search_limit > limit else 'normal'})")
        print(f"   - Sin score_threshold (compatible con n8n)")
        
        response = requests.post(
            f"{qdrant_url}/collections/{collection_name}/points/search",
            headers=headers,
            json=payload,
            timeout=10
        )
        
        print(f"üì° Respuesta de Qdrant: Status {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            points = data.get('result', [])
            
            print(f"ÔøΩ Resultados encontrados: {len(points)}")
            
            # Si hay fecha espec√≠fica y no encontramos el documento exacto, hacer scroll search
            if target_date:
                dia_semana_target = dias[target_date.weekday()]
                dia_numero_target = str(target_date.day)
                mes_target = meses[target_date.month - 1]
                
                # Buscar si alguno de los resultados es match exacto
                has_exact_match = False
                for point in points:
                    content = point.get('payload', {}).get('content', '')
                    content_lower = content.lower()
                    if (dia_semana_target.lower() in content_lower and 
                        dia_numero_target in content and 
                        mes_target in content_lower):
                        has_exact_match = True
                        break
                
                # Si NO encontramos match exacto, hacer scroll para buscarlo
                if not has_exact_match:
                    print(f"‚ö†Ô∏è  No se encontr√≥ match exacto en los {len(points)} resultados vectoriales")
                    print(f"üîÑ Ejecutando scroll search para encontrar: {dia_semana_target} {dia_numero_target} de {mes_target}")
                    
                    try:
                        scroll_payload = {
                            "limit": 200,  # Aumentado a 200 para cubrir toda la colecci√≥n (124 docs actuales)
                            "with_payload": True,
                            "with_vector": False
                        }
                        
                        scroll_response = requests.post(
                            f"{qdrant_url}/collections/{collection_name}/points/scroll",
                            headers=headers,
                            json=scroll_payload,
                            timeout=10
                        )
                        
                        if scroll_response.status_code == 200:
                            scroll_data = scroll_response.json()
                            scroll_points = scroll_data.get('result', {}).get('points', [])
                            print(f"üìú Scroll encontr√≥ {len(scroll_points)} documentos en total")
                            print(f"üîç Buscando coincidencia exacta de: '{dia_semana_target}' + '{dia_numero_target}' + '{mes_target}'")
                            
                            # Buscar el documento con fecha exacta
                            found_match = False
                            for scroll_point in scroll_points:
                                content = scroll_point.get('payload', {}).get('content', '')
                                content_lower = content.lower()
                                
                                # Debug: mostrar primeros 100 caracteres de cada documento revisado
                                if 'lecci√≥n 6' in content_lower and 'noviembre' in content_lower:
                                    print(f"   üîé Revisando: {content[:120]}...")
                                
                                if (dia_semana_target.lower() in content_lower and 
                                    dia_numero_target in content and 
                                    mes_target in content_lower):
                                    
                                    print(f"‚úÖ ¬°ENCONTRADO en scroll! Agregando al inicio de resultados")
                                    print(f"   ID: {scroll_point.get('id')}")
                                    print(f"   Contenido: {content[:150]}...")
                                    
                                    # Agregar este documento al inicio con score alto
                                    points.insert(0, {
                                        'id': scroll_point.get('id'),
                                        'score': 1.5,  # Score artificial alto para priorizarlo
                                        'payload': scroll_point.get('payload', {})
                                    })
                                    found_match = True
                                    break
                            
                            if not found_match:
                                print(f"‚ùå No se encontr√≥ documento con: {dia_semana_target} {dia_numero_target} de {mes_target}")
                    except Exception as scroll_error:
                        print(f"‚ö†Ô∏è  Error en scroll search: {scroll_error}")
            
            if not points:
                print("‚ö†Ô∏è  No se encontraron documentos relevantes")
                print("   Esto puede significar que:")
                print("   1. La colecci√≥n est√° vac√≠a (points_count = 0)")
                print("   2. El score threshold es muy alto")
                print("   3. Los embeddings no coinciden (diferentes task_types)")
                return []
            
            # Primero, construir la lista de documentos con scores
            doc_candidates = []
            for point in points:
                payload = point.get('payload', {})
                content = payload.get('content', payload.get('text', ''))
                
                if content:
                    score = point.get('score', 0)
                    doc_candidates.append({
                        'point': point,
                        'content': content,
                        'score': score,
                        'payload': payload
                    })
            
            # RE-RANKING: Si la pregunta tiene fecha espec√≠fica, priorizar documentos con esa fecha
            if target_date:  # Si se detect√≥ una referencia temporal
                print(f"üéØ Aplicando re-ranking por coincidencia de fecha exacta...")
                
                # Extraer los componentes de la fecha objetivo
                dia_semana = dias[target_date.weekday()]
                dia_numero = str(target_date.day)
                mes_actual = meses[target_date.month - 1]
                
                # Re-ordenar documentos: los que contienen la fecha exacta van primero
                exact_matches = []
                partial_matches = []
                other_docs = []
                
                for doc in doc_candidates:
                    content_lower = doc['content'].lower()
                    
                    # Coincidencia EXACTA: contiene d√≠a de semana + n√∫mero + mes
                    if (dia_semana.lower() in content_lower and 
                        dia_numero in doc['content'] and 
                        mes_actual in content_lower):
                        # BOOST: dar score adicional a coincidencias exactas
                        doc['score'] = doc['score'] + 0.5  
                        exact_matches.append(doc)
                        print(f"   ‚úÖ MATCH EXACTO: {doc['content'][:100]}... (score: {doc['score']:.3f})")
                    # Coincidencia PARCIAL: solo d√≠a de semana o solo n√∫mero+mes
                    elif (dia_semana.lower() in content_lower or 
                          (dia_numero in doc['content'] and mes_actual in content_lower)):
                        doc['score'] = doc['score'] + 0.2
                        partial_matches.append(doc)
                        print(f"   üî∏ MATCH PARCIAL: {doc['content'][:100]}... (score: {doc['score']:.3f})")
                    else:
                        other_docs.append(doc)
                        print(f"   üìÑ Doc encontrado (score: {doc['score']:.3f}): {doc['content'][:100]}...")
                
                # Combinar: exact matches primero, luego partial, luego otros
                doc_candidates = exact_matches + partial_matches + other_docs
            else:
                # Sin enriquecimiento de fecha, solo mostrar scores
                for doc in doc_candidates:
                    print(f"   üìÑ Doc encontrado (score: {doc['score']:.3f}): {doc['content'][:100]}...")
            
            # Convertir a objetos Document
            relevant_docs = []
            for doc in doc_candidates[:limit]:  # Limitar al n√∫mero solicitado
                relevant_docs.append(Document(
                    doc_id=str(doc['point'].get('id', '')),
                    content=doc['content'],
                    metadata=doc['payload'].get('metadata', {})
                ))
            
            print(f"üìö Total de documentos procesados: {len(relevant_docs)}")
            return relevant_docs
        else:
            print(f"‚ùå Error en la b√∫squeda de Qdrant: {response.status_code} - {response.text}")
            return []
            
    except Exception as e:
        print(f"‚ùå Error en get_documents: {e}")
        import traceback
        traceback.print_exc()
        return []
